{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unittest\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoss(unittest.TestCase):\n",
    "\n",
    "  def test_zero_h_zero_y(self):\n",
    "    self.assertAlmostEqual(loss(h=np.array([0]), y=np.array([0])), 0)\n",
    "\n",
    "  def test_one_h_zero_y(self):\n",
    "    self.assertAlmostEqual(loss(h=np.array([1]), y=np.array([0])), 0.5)\n",
    "\n",
    "  def test_two_h_zero_y(self):\n",
    "    self.assertAlmostEqual(loss(h=np.array([2]), y=np.array([0])), 2)\n",
    "    \n",
    "  def test_zero_h_one_y(self):\n",
    "    self.assertAlmostEqual(loss(h=np.array([0]), y=np.array([1])), 0.5)\n",
    "    \n",
    "  def test_zero_h_two_y(self):\n",
    "    self.assertAlmostEqual(loss(h=np.array([0]), y=np.array([2])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "  sq_error = (h - y)**2\n",
    "  n = len(y)\n",
    "  return 1.0 / (2*n) * sq_error.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31864\\2617624882.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create DataFrame with feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Sharon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[0;32m   2421\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\Sharon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2097\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2098\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   2099\u001b[0m             \u001b[1;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m             \u001b[1;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "x = df[['rooms', 'area_size']]\n",
    "y = df['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create DataFrame with feature names\n",
    "feature_names = ['rooms', 'area_size']\n",
    "x_train = pd.DataFrame(x_train, columns=feature_names)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLinearRegression(unittest.TestCase):\n",
    "\n",
    "    def test_find_coefficients(self):\n",
    "      clf = LinearRegression()\n",
    "      clf.fit(x, y, n_iter=2000, lr=0.01)\n",
    "      np.testing.assert_array_almost_equal(clf._W, np.array([180921.19555322,  56294.90199925]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "  \n",
    "  def predict(self, X):\n",
    "    return np.dot(X, self._W)\n",
    "\n",
    "  def _gradient_descent_step(self, X, targets, lr):\n",
    "    predictions = self.predict(X)\n",
    "    error = predictions - targets\n",
    "    gradient = np.dot(X.T, error) / len(X)\n",
    "    self._W -= lr * gradient\n",
    "\n",
    "  def fit(self, X, y, n_iter=100000, lr=0.01):\n",
    "\n",
    "    self._W = np.zeros(X.shape[1])\n",
    "\n",
    "    for i in range(n_iter):        \n",
    "        self._gradient_descent_step(x, y, lr)       \n",
    "        \n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(x, y, n_iter=2000, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colorbar as cbar\n",
    "\n",
    "# Set the feature names of x_test\n",
    "x_test.columns = ['rooms', 'area_size']\n",
    "\n",
    "# Set a common color for the scatter plots\n",
    "scatter_color = 'steelblue'\n",
    "\n",
    "# Plotting the scatter plot with the regression line\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(x_test['rooms'], y_test, color=scatter_color, label='Actual', alpha=0.7, edgecolors='k')\n",
    "ax.scatter(x_test['rooms'], y_pred, color='red', label='Predicted', alpha=0.7, edgecolors='k')\n",
    "ax.set_xlabel('Number of Rooms')\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_title('Linear Regression')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the contour plot\n",
    "x_range = np.linspace(np.min(x['rooms']), np.max(x['rooms']), 100)\n",
    "y_range = np.linspace(np.min(x['area_size']), np.max(x['area_size']), 100)\n",
    "x_mesh, y_mesh = np.meshgrid(x_range, y_range)\n",
    "z_mesh = model.predict(np.array([x_mesh.ravel(), y_mesh.ravel()]).T).reshape(x_mesh.shape)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Scatter plot of training data\n",
    "axs[0, 0].scatter(x_train['rooms'], y_train, color=scatter_color, alpha=0.7, edgecolors='k')\n",
    "axs[0, 0].set_xlabel('Number of Rooms')\n",
    "axs[0, 0].set_ylabel('Price')\n",
    "axs[0, 0].set_title('Training Data')\n",
    "\n",
    "# Scatter plot of testing data\n",
    "axs[0, 1].scatter(x_test['rooms'], y_test, color=scatter_color, alpha=0.7, edgecolors='k')\n",
    "axs[0, 1].set_xlabel('Number of Rooms')\n",
    "axs[0, 1].set_ylabel('Price')\n",
    "axs[0, 1].set_title('Testing Data')\n",
    "\n",
    "# Predicted values scatter plot\n",
    "axs[1, 0].scatter(x_test['rooms'], y_pred, color='red', alpha=0.7, edgecolors='k')\n",
    "axs[1, 0].set_xlabel('Number of Rooms')\n",
    "axs[1, 0].set_ylabel('Price')\n",
    "axs[1, 0].set_title('Predicted Values')\n",
    "\n",
    "# Contour plot\n",
    "contour = axs[1, 1].contourf(x_mesh, y_mesh, z_mesh, levels=20, cmap='coolwarm')\n",
    "axs[1, 1].scatter(x_test['rooms'], x_test['area_size'], color=scatter_color, alpha=0.7, edgecolors='k')\n",
    "axs[1, 1].set_xlabel('Number of Rooms')\n",
    "axs[1, 1].set_ylabel('Area Size')\n",
    "axs[1, 1].set_title('Contour Plot')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(contour, ax=axs[1, 1])\n",
    "cbar.set_label('Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
